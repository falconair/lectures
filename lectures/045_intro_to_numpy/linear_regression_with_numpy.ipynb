{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sklearn.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Numpy (only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read the file containing our data\n",
    "Pandas provides an easier way to read the data and convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = sklearn.datasets.load_diabetes(as_frame=True).data\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = data_df.values\n",
    "data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data_arr[:,1:] # get everything but the first column\n",
    "y_raw = data_arr[:, :1]# get the first column (I'm not just doing data_arr[:,-1] to avoid (x,) dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.shape, y_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_raw = X_raw / X_raw.sum()\n",
    "#y_raw = y_raw / y_raw.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bias to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones(y_raw.shape),X_raw))\n",
    "y = y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use gradient descent to solve for coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "iterations = 100_000\n",
    "\n",
    "features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.ones((features,1))\n",
    "\n",
    "for i in range(iterations):\n",
    "    w -= (learning_rate) * (2) * X.T.dot(X.dot(w) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = X.shape[0]\n",
    "np.sum((X.dot(w) - y)**2)/ (observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try again, but do a grid search for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [0.001, 0.0001, 0.00001]\n",
    "iteration_list = [100, 1_000, 10_000, 100_000]\n",
    "\n",
    "hyper_parameters = list()\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "    print(f\"Trying learning rate {learning_rate} and batch size {iterations}\")\n",
    "    for iterations in iteration_list:\n",
    "        w = np.ones((features,1))\n",
    "        for i in range(iterations):\n",
    "            w -= (learning_rate) * (2) * X.T.dot(X.dot(w) - y)\n",
    "            error = np.sum(X.dot(w) - y) # not squared to avoid overflow error\n",
    "        hyper_parameters.append((learning_rate, iterations, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaner version of the same code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, iterations=10000, learning_rate=0.0001, callback=None, callback_freq=100_000):\n",
    "\n",
    "    observations = X.shape[0]\n",
    "    features = X.shape[1]\n",
    "\n",
    "    w = np.ones((features,1))\n",
    "\n",
    "    predictor = lambda X: X.dot(w)\n",
    "    mse       = lambda X, y: np.sum((predictor(X) - y)**2)/observations\n",
    "\n",
    "    errors = np.zeros(iterations)\n",
    "    for i in range(iterations): \n",
    "        prediction = predictor(X)\n",
    "        error = prediction - y\n",
    "        errors[i] = mse(X, y)\n",
    "        if callback and i % callback_freq == 0: callback(i, w, errors[i])\n",
    "        #gradient = (2/observations) * X.T.dot(error)\n",
    "        gradient =  2 * X.T.dot(error)\n",
    "        w -= learning_rate * gradient\n",
    "    \n",
    "    return predictor, w, mse, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "learning_rate_list = [0.001, 0.0001]\n",
    "iteration_list = [10, 100, 1_000, 10_000, 100_000]\n",
    "\n",
    "callback = lambda i, w, e:print(e)\n",
    "\n",
    "hyper_parameters = list()\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "    for iterations in iteration_list:\n",
    "        \n",
    "        print(f\"Trying learning rate {learning_rate} and batch size {iterations}\")\n",
    "        \n",
    "        predictor, w, mse, errors = fit(X, y, iterations = iterations, learning_rate=learning_rate, callback=None)\n",
    "        hyper_parameters.append((learning_rate, iterations, mse(X, y), errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'a':1, 'b':2, 'c':[1,2,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "for hp in hyper_parameters:\n",
    "    lr, epoch, mse, errors = hp\n",
    "    error_indexes = list(range(len(errors)))\n",
    "    dfs.append(pd.DataFrame({'lr':lr, 'epoch':epoch, 'mse':mse, 'error':errors, 'error_indexes':error_indexes}))\n",
    "\n",
    "hyper_parameters_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='error_indexes'\n",
    "            , y='error'\n",
    "            , col='lr'\n",
    "            , row='epoch'\n",
    "            , data=hyper_parameters_df\n",
    "            , kind='line'\n",
    "            , facet_kws={'sharey':False, 'sharex':False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%time reg = LinearRegression(fit_intercept=False).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, X.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
